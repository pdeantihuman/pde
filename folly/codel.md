# CoDel

CoDel(Controlled Delay受控延迟)是一种来自网络的主动队列管理算法，用于对抗缓冲块。

服务也有队列(请求队列，而不是数据包队列)，并且在过载时会出现排队延迟。这个类为服务调整代码算法。

Codel在网络[1，2]上有深入的讨论，但是算法的基本草图是这样的:如果在过去的时间间隔(100毫秒)内，每个请求都经历了大于目标(5毫秒)的排队延迟，那么我们就可以卸载。

我们已经修改了代码算法。TCP通过响应丢失的数据包而改变窗口来减轻负载。网络设置中的Codel以越来越短的间隔(100 / sqrt(n))丢弃数据包，以实现吞吐量的线性变化。根据我们的经验，一个不同的方案对服务更有效:当过载时，我们会丢弃超出一个可选超时(2 * target_delay)的出列请求。

因此，总之，要使用这个类，计算每个请求在队列中花费的时间，并将该延迟提供给overloaded()，这将告诉您是否终止这个请求。

您还可以要求瞬时负载估计值和在此间隔内观察到的最小延迟。

## wiki

在网络路由中，受控延迟的CoDel(发音为“coddle”)是范·雅各布森(Van Jacobson)和凯瑟琳·尼科尔斯(Kathleen Nichols)开发的网络调度器的调度算法。它旨在克服网络硬件(如路由器)中的缓冲区问题，方法是设置网络数据包通过该设备缓冲区时的延迟限制。CoDel旨在通过解决雅各布森认为的随机早期检测(RED)算法的一些基本误解，并通过更易于管理来提高其整体性能。

2012年，戴夫·泰特(Dave Tht)和埃里克·杜马斯特(Eric Dumazet)为Linux内核编写了CoDel的实现，并根据GNU通用公共许可证和3条款BSD许可证进行了双重许可。Dumazet的CoDel变体称为fq_codel，代表“公平排队控制延迟”；它被称为“障碍断路器Barrier Breaker”的OpenWrt版本用作标准主动队列管理(AQM)和数据包调度解决方案。从那时起，CoDel和fq_codel已经迁移到各种下游项目中，例如Tomato、dd-wrt和OPNsense。

### 理论根据

CoDel背后的理论是基于对数据缓冲区影响下分组交换网络中分组行为的观察。这些观察中的一些是关于排队的基本性质和bufferbloat的原因，另一些是关于替代队列管理算法的弱点。CoDel的开发是为了解决bufferbloat问题。[1]

#### bufferbloat问题

当数据包在快速网络和慢速网络之间的网络链路上传输时，尤其是在传输控制协议会话开始时，当数据包突然突发，而慢速网络可能无法足够快地接受突发时，数据包的流量会变慢。缓冲区的存在是为了缓解这个问题，它为快速网络提供了一个存储数据包的地方，以便慢速网络以自己的速度读取数据包。[2]换句话说，缓冲器就像减震器一样，将突发的到达转变成平稳的离开。然而，缓冲区的容量有限。理想的缓冲区大小是这样的，它可以处理突发的通信，并将突发的速度与较慢网络的速度相匹配。理想情况下，冲击吸收情况的特征在于传输突发期间缓冲器中的分组的临时延迟，此后延迟迅速消失，网络在提供和处理分组方面达到平衡。[2]

TCP拥塞控制算法依赖数据包丢弃来确定两个通信设备之间的可用带宽。它加速数据传输，直到数据包开始丢失，然后降低传输速率。理想情况下，当它在链路速度上找到平衡时，它会不断加速和减速。为此，数据包丢弃必须及时发生，以便算法能够相应地选择合适的传输速度。由于数据包保存在过大的缓冲区中，数据包将到达目的地，但延迟较高，但不会丢失数据包，因此TCP不会变慢。在这些条件下，TCP甚至可以决定连接的路径已经改变，并重复寻找新的平衡。

拥有一个大的、持续满的缓冲区会导致传输延迟增加和交互性降低，尤其是在同一信道上同时传输两个或多个数据时，这种情况称为缓冲区。可用的信道带宽也可能最终未被使用，因为一些快速目的地可能无法到达，因为缓冲区被等待传送到慢速目的地的数据堵塞。

## BufferBloat

缓冲区是分组交换网络中高延迟的一个原因，这是由分组的过度缓冲引起的。缓冲区也可能导致数据包延迟变化(也称为抖动)，并降低整体网络吞吐量。当路由器或交换机被配置为使用过大的缓冲区时，即使非常高速的网络实际上也可能无法用于许多交互式应用，如网络电话、在线游戏甚至普通的网上冲浪。

一些通信设备制造商为他们的一些网络产品设计了不必要的大缓冲器。在这种设备中，当网络链路变得拥塞时，bufferbloat就会出现，导致数据包在这些超大缓冲区中长时间排队。在先进先出排队系统中，过大的缓冲区会导致更长的队列和更高的延迟，并且不会提高网络吞吐量。

bufferbloat现象早在1985年就有描述。从2009年开始，它获得了更广泛的关注。

### 缓冲

网络设备制造商的经验法则是提供足够大的缓冲区，以便为通过设备的数据流提供至少250毫秒的缓冲。例如，路由器的千兆以太网接口需要相对较大的32 MB缓冲区。[3]缓冲区的这种大小可能导致TCP拥塞控制算法失败。

这里发生了什么事呢，首先网络的处理速度是和应用程序相关的，而不是只和链路的速度相关。如果缓冲区过大，TCP的拥塞控制算法慢开始时就会以为接收方的消费速度很快(达到了链路的上限)，但是缓冲区满时才开始拒绝数据包，导致TCP的拥塞控制算法并不能测算出实际的恰当消费速度。

然后，在拥塞控制重置和TCP连接加速并再次填充缓冲区之前，缓冲区需要一些时间才能耗尽。因此，缓冲区会导致诸如高延迟和可变延迟等问题，并且当缓冲区充满一个TCP流的数据包并且其他数据包随后被丢弃时，会阻塞所有其他流的网络瓶颈。

膨胀的缓冲区只有在实际使用时才有效果。换句话说，只有当缓冲的链路成为瓶颈时，过大的缓冲区才会产生破坏性影响。服务瓶颈的缓冲区大小可以使用大多数操作系统提供的ping实用程序来测量。首先，另一个主机应该被连续pinged通；然后，应该开始并停止几次几秒钟长的下载。根据设计，TCP拥塞避免算法将快速填补路由上的瓶颈。如果下载(和上传分别)与ping报告的往返时间的直接和重要增加相关，则表明下载(和上传分别)方向的当前瓶颈缓冲区膨胀。由于往返时间的增加是由瓶颈上的缓冲区引起的，最大增加量给出了以毫秒为单位的粗略估计。[6]

在前面的例子中，使用高级traceroute工具而不是简单的ping(例如，MTR)不仅可以证明瓶颈上存在膨胀的缓冲区，还可以确定它在网络中的位置。Traceroute通过显示路由(路径)和测量数据包通过网络的传输延迟来实现这一点。路由的历史记录为从路由(路径)中每个连续主机(远程节点)接收的数据包的往返时间。[7]

Bufferbloat问题指的是缓冲区太大了，网络拥塞时交互性变得很差。如果有很多个任务在共用一个缓冲队列，这个队列上某些程序占用了队列的大量空间，导致其他交互性要求更高的程序无法使用队列。缓冲区实际上相当于一个FIFO队列。如果队列太长了，那么交互性比较高的程序就必须排很长时间的队。

解决方法有以下方法

1. 多队列管理。改成有多个FIFO队列，有的优先级高有的优先级低。
2. NAPI方式。
3. 命名空间方式。
4. SMP方式。
5. Controlled Delay CoDel算法。队列中排队的数据包过多时开始丢弃数据包。Codel算法的原理是从队列开头有选择地丢弃数据包，而不是处理不完了就开始丢弃尾部的数据包。基本思想是，查看每个数据包的等待时间，如果等待超过5ms, 说明队列可能拥堵了，丢弃该数据包。可以降低TCP拥塞控制部分的负荷。